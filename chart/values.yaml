global:
  commonAnnotations: {}
  commonLabels: 
    tenancy.io/stack: k3s-argocd 
    tenancy.io/tenant: test

  # Default network policy rules used by all components
  networkPolicy:
    # -- Create NetworkPolicy objects for all components
    create: true
    # -- Default deny all ingress traffic
    defaultDenyIngress: false

enabled: true

namespace:
  # If enabled the release namespace will be managed by manifest in this chart.
  # it is recommended to manage namespaces from the argocd applications instead.
  enabled: false

destination:
  # Destinations to deploy this chart to
  server: https://kubernetes.default.svc

# Default argocd project that always exists.
defaultProject:
  # Enabling the default project will apply the manifest and lock down
  # the default project so nothing can be added to it. Make sure to 
  # disable this during bootstrapping.
  enabled: false

# Project argocd is installed in.
argocdProject: 
  enabled: true
  name: argocd
  # commonLabels: {}
  # commonAnnotations: {}
  repos:
    # Argocd Helm chart repository
    - https://argoproj.github.io/argo-helm
    # This repo
    - https://github.com/Nynra/k3s-argocd
  clusterResourceWhitelist:
    - group: "*"
      kind: "*"
  namespaceResourceWhitelist:
    - group: "*"
      kind: "*"
  warnOrphanedResources: true

# Repositories that will be added to the bootstrapping project.
bootstrapProject: 
  enabled: true
  name: infrastructure
  # commonLabels: {}
  # commonAnnotations: {}
  namespaces:
    - "*"
  repos:
    - https://github.com/Nynra/k3s-traefik
    - https://github.com/Nynra/k3s-certs
    - https://github.com/Nynra/k3s-storage
    - https://github.com/Nynra/k3s-kube-prometheus-stack
    # This repo
    - https://github.com/Nynra/k3s-argocd
  clusterResourceWhitelist:
    - group: "*"
      kind: "*"
  namespaceResourceWhitelist:
    - group: "*"
      kind: "*"
  warnOrphanedResources: false

tenantManagementProject: 
  enabled: false
  name: tenant-management
  # commonLabels: {}
  # commonAnnotations: {}
  namespaces:
    - "*"
  repos:
    # This repo
    - https://github.com/Nynra/k3s-argocd
  clusterResourceWhitelist:
    - group: "*"
      kind: "*"
  namespaceResourceWhitelist:
    - group: "*"
      kind: "*"
  warnOrphanedResources: false

dashboard:
  enabled: false
  ingressUrl: argocd.example.com
  entrypoint: websecure
  middlewares:
    - name: traefik-default-chain
      namespace: traefik
  cert:
    externalSecret: 
      enabled: false
      secretName: argocd-dashboard-tls
      secretStore: kubernetes
      secretStoreType: "ClusterSecretStore"
    reflectedSecret: 
      enabled: true
      originNamespace: certs
      originSecretName: argocd-dashboard-tls

# metricsExtension:
#   enabled: false
#   prometheusAddress: "http://prom-stack-kube-prometheus-prometheus.monitoring.svc:9090"

# Values for the ArgoCD Helm chart.
argo-cd: 
  enabled: false
  configs: 
    params: 
      server.enable.proxy.extension: "true"
      # TLS termination is handled by Traefik, so we disable the TLS server in ArgoCD.
      server.insecure: false

      # -- Enables [Applications in any namespace]
      ## List of additional namespaces where applications may be created in and reconciled from.
      ## The namespace where Argo CD is installed to will always be allowed.
      ## Set comma-separated list. (e.g. app-team-one, app-team-two)
      application.namespaces: ""

    rbac: 
      policy.csv: |
        p, role:org-admin, applications, *, */*, allow
        p, role:org-admin, clusters, get, *, allow
        p, role:org-admin, repositories, *, *, allow
        p, role:org-admin, logs, get, *, allow
        p, role:org-admin, exec, create, */*, allow
        p, role:readonly, extensions, invoke, metrics, allow
    cm: 
      extension.config: |
        extensions:
          - name: metrics
            backend:
              services:
                - url: http://argocd-metrics-server.argocd.svc:9003

      # Argocd Health Checks
      resource.customizations.health.argoproj.io_Application: |
        hs = {}
        hs.status = "Progressing"
        hs.message = ""
        if obj.status ~= nil then
          if obj.status.health ~= nil then
            hs.status = obj.status.health.status
            if obj.status.health.message ~= nil then
              hs.message = obj.status.health.message
            end
          end
        end
        return hs

      # Cert Manager Health Checks
      resource.customizations.health.cert-manager.io_Certificate: |
        local hs = {}
        if obj.status ~= nil then
          if obj.status.conditions ~= nil then

            -- Always Handle Issuing First to ensure consistent behaviour
            for i, condition in ipairs(obj.status.conditions) do
              if condition.type == "Issuing" and condition.status == "True" then
                hs.status = "Progressing"
                hs.message = condition.message
                return hs
              end
            end

            for i, condition in ipairs(obj.status.conditions) do
              if condition.type == "Ready" and condition.status == "False" then
                hs.status = "Degraded"
                hs.message = condition.message
                return hs
              end
              if condition.type == "Ready" and condition.status == "True" then
                hs.status = "Healthy"
                hs.message = condition.message
                return hs
              end
            end
          end
        end

        hs.status = "Progressing"
        hs.message = "Waiting for certificate"
        return hs

      resource.customizations.health.cert-manager.io_Issuer: |
        local hs = {}
        if obj.status ~= nil then
          if obj.status.conditions ~= nil then
            for i, condition in ipairs(obj.status.conditions) do
              if condition.type == "Ready" and condition.status == "False" then
                hs.status = "Degraded"
                hs.message = condition.message
                return hs
              end
              if condition.type == "Ready" and condition.status == "True" then
                hs.status = "Healthy"
                hs.message = condition.message
                return hs
              end
            end
          end
        end

        hs.status = "Progressing"
        hs.message = "Initializing issuer"
        return hs

      resource.customizations.health.cert-manager.io_ClusterIssuer: |
        local hs = {}
        if obj.status ~= nil then
          if obj.status.conditions ~= nil then
            for i, condition in ipairs(obj.status.conditions) do
              if condition.type == "Ready" and condition.status == "False" then
                hs.status = "Degraded"
                hs.message = condition.message
                return hs
              end
              if condition.type == "Ready" and condition.status == "True" then
                hs.status = "Healthy"
                hs.message = condition.message
                return hs
              end
            end
          end
        end

        hs.status = "Progressing"
        hs.message = "Initializing ClusterIssuer"
        return hs
      
      # External Secrets Operator Health Checks
      resource.customizations.health.external-secrets.io_ExternalSecret: |
        local hs = {}
        if obj.status ~= nil then
          if obj.status.conditions ~= nil then
            for i, condition in ipairs(obj.status.conditions) do
              if condition.type == "Ready" and condition.status == "False" then
                hs.status = "Degraded"
                hs.message = condition.message
                return hs
              end
              if condition.type == "Ready" and condition.status == "True" then
                hs.status = "Healthy"
                hs.message = condition.message
                return hs
              end
            end
          end
        end
        hs.status = "Progressing"
        hs.message = "Waiting for ExternalSecret"
        return hs
      
      resource.customizations.health.external-secrets.io_PushSecret: |
        hs = {}
        if obj.status ~= nil then
          if obj.status.conditions ~= nil then
            for i, condition in ipairs(obj.status.conditions) do
              if condition.type == "Ready" and condition.status == "False" then
                hs.status = "Degraded"
                hs.message = condition.message
                return hs
              end
              if condition.type == "Ready" and condition.status == "True" then
                hs.status = "Healthy"
                hs.message = condition.message
                return hs
              end
            end
          end
        end
        hs.status = "Progressing"
        hs.message = "Waiting for PushSecret"
        return hs

      resource.customizations.health.external-secrets.io_SecretStore: |
        local hs = {}
        if obj.status ~= nil then
          if obj.status.conditions ~= nil then
            for i, condition in ipairs(obj.status.conditions) do
              if condition.type == "Ready" and condition.status == "False" then
                hs.status = "Degraded"
                hs.message = condition.message
                return hs
              end
              if condition.type == "Ready" and condition.status == "True" then
                hs.status = "Healthy"
                hs.message = condition.message
                return hs
              end
            end
          end
        end
        hs.status = "Progressing"
        hs.message = "Waiting for SecretStore"
        return hs

      resource.customizations.health.external-secrets.io_ClusterExternalSecret: |
        local hs = {}
        if obj.status ~= nil then
          if obj.status.conditions ~= nil then
            -- For ClusterExternalSecret, new statuses are appended to the end of the list
            local lastStatus = obj.status.conditions[#obj.status.conditions]
            if lastStatus.type == "Ready" and lastStatus.status == "True" then
              hs.status = "Healthy"
              hs.message = lastStatus.message
              return hs
            end
            if lastStatus.type == "PartiallyReady" and lastStatus.status == "True" then
              hs.status = "Degraded"
              hs.message = lastStatus.message
              return hs
            end
            if lastStatus.type == "NotReady" and lastStatus.status == "True" then
              hs.status = "Degraded"
              hs.message = lastStatus.message
              return hs
            end
          end
        end
        hs.status = "Progressing"
        hs.message = "Waiting for ClusterExternalSecret"
        return hs

      resource.customizations.health.external-secrets.io_ClusterSecretStore: |
        local hs = {}
        if obj.status ~= nil then
          if obj.status.conditions ~= nil then
            for i, condition in ipairs(obj.status.conditions) do
              if condition.type == "Ready" and condition.status == "False" then
                hs.status = "Degraded"
                hs.message = condition.message
                return hs
              end
              if condition.type == "Ready" and condition.status == "True" then
                hs.status = "Healthy"
                hs.message = condition.message
                return hs
              end
            end
          end
        end
        hs.status = "Progressing"
        hs.message = "Waiting for ClusterSecretStore"
        return hs

  server:
    # This is the correct location for the initContainer
    InitContainers:
      - name: install-metrics-extension
        image: quay.io/argoprojlabs/argocd-extension-installer:v0.0.8
        env:
          - name: EXTENSION_URL
            value: https://github.com/argoproj-labs/argocd-extension-metrics/releases/download/v1.0.3/extension.tar.gz
          - name: EXTENSION_CHECKSUM_URL
            value: https://github.com/argoproj-labs/argocd-extension-metrics/releases/download/v1.0.3/extension_checksums.txt
        volumeMounts:
          - name: extensions-dir
            mountPath: /tmp/extensions/
        securityContext:
          runAsUser: 1000
          allowPrivilegeEscalation: false

    # This is the correct location for the volumeMount on the main container
    VolumeMounts:
      - name: extensions-dir
        mountPath: /tmp/extensions/

    # This is the correct location for the volume definition
    Volumes:
      - name: extensions-dir
        emptyDir: {}